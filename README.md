# ü§ñ Google Business Scraper

Um scraper Python robusto para extrair informa√ß√µes de neg√≥cios do Google usando Scrapy. Extrai dados como nome, avalia√ß√£o, n√∫mero de reviews, localiza√ß√£o e categoria de empresas.

## üìã Funcionalidades

- ‚úÖ Busca autom√°tica no Google por neg√≥cios locais
- ‚úÖ Extra√ß√£o de dados estruturados (nome, avalia√ß√£o, reviews, localiza√ß√£o)
- ‚úÖ Exporta√ß√£o autom√°tica para Excel (.xlsx)
- ‚úÖ Rota√ß√£o de User-Agents para evitar bloqueios
- ‚úÖ Sistema de retry e throttling inteligente
- ‚úÖ Logs detalhados e sistema de debug
- ‚úÖ Suporte a m√∫ltiplos seletores CSS
- ‚úÖ Tratamento robusto de erros

## üõ†Ô∏è Tecnologias Utilizadas

- **Python 3.8+**
- **Scrapy** - Framework de web scraping
- **OpenPyXL** - Manipula√ß√£o de arquivos Excel
- **Fake-UserAgent** - Rota√ß√£o de user agents
- **Brotli** - Suporte a compress√£o

## üì¶ Instala√ß√£o

### 1. Clone o reposit√≥rio
```bash
git clone https://github.com/Charlinho/google-business-scraper.git
cd google-business-scraper-scrapy
```

### 2. Crie um ambiente virtual
```bash
# Windows
python -m venv venv
venv\Scripts\activate

# macOS/Linux
python3 -m venv venv
source venv/bin/activate
```

### 3. Instale as depend√™ncias
```bash
pip install -r requirements.txt

### 4. Verifique a instala√ß√£o
```bash
scrapy version
```

## üöÄ Como Usar

### Comando B√°sico
```bash
python3 run_scraper.py --search "sal√£o de beleza atibaia" --max-results 50
```

### Exemplos de Uso

#### Buscar restaurantes italianos em S√£o Paulo
```bash
python3 run_scraper.py --search "restaurante italiano s√£o paulo" --max-results 100
```

#### Buscar academias no Rio de Janeiro
```bash
python3 run_scraper.py --search "academia rio de janeiro" --max-results 75
```

#### Buscar cl√≠nicas veterin√°rias em Belo Horizonte
```bash
python3 run_scraper.py --search "cl√≠nica veterin√°ria belo horizonte" --max-results 30
```

### Par√¢metros Dispon√≠veis

| Par√¢metro | Descri√ß√£o | Exemplo | Padr√£o |
|-----------|-----------|---------|---------|
| `--search` | Termo de busca | `"sal√£o de beleza atibaia"` | `"sal√£o de beleza atibaia"` |
| `--max-results` | N√∫mero m√°ximo de resultados | `100` | `50` |

## üìÅ Estrutura do Projeto

```
google-business-scraper-scrapy/
‚îú‚îÄ‚îÄ google_business_scraper/
‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îú‚îÄ‚îÄ items.py              # Defini√ß√£o dos itens de dados
‚îÇ   ‚îú‚îÄ‚îÄ middlewares.py        # Middleware personalizado
‚îÇ   ‚îú‚îÄ‚îÄ pipelines.py          # Pipeline de processamento
‚îÇ   ‚îú‚îÄ‚îÄ settings.py           # Configura√ß√µes do Scrapy
‚îÇ   ‚îî‚îÄ‚îÄ spiders/
‚îÇ       ‚îú‚îÄ‚îÄ __init__.py
‚îÇ       ‚îî‚îÄ‚îÄ business_spider.py # Spider principal
‚îú‚îÄ‚îÄ data/                     # Arquivos Excel gerados
‚îú‚îÄ‚îÄ debug_page.html          # HTML de debug (gerado automaticamente)
‚îú‚îÄ‚îÄ requirements.txt         # Depend√™ncias b√°sicas
‚îú‚îÄ‚îÄ requirements_with_brotli.txt # Depend√™ncias com suporte Brotli
‚îú‚îÄ‚îÄ run_scraper.py          # Script principal de execu√ß√£o
‚îú‚îÄ‚îÄ test_pipeline.py        # Script de teste
‚îî‚îÄ‚îÄ README.md              # Este arquivo
```

## üìä Dados Extra√≠dos

O scraper extrai as seguintes informa√ß√µes para cada neg√≥cio:

| Campo | Descri√ß√£o | Exemplo |
|-------|-----------|---------|
| **Nome** | Nome do estabelecimento | "Sal√£o Beleza & Estilo" |
| **Avalia√ß√£o** | Nota m√©dia (0-5 estrelas) | "4.5" |
| **N√∫mero de Avalia√ß√µes** | Quantidade de reviews | "127" |
| **Localiza√ß√£o** | Endere√ßo ou bairro | "Centro, Atibaia - SP" |
| **Categoria** | Tipo de neg√≥cio | "Sal√£o" |
| **URL** | Link (quando dispon√≠vel) | "https://..." |

## üìà Arquivo de Sa√≠da

Os dados s√£o salvos automaticamente em:
```
data/[termo_da_busca].xlsx
```

**Exemplo:**
- Busca: `"restaurante italiano s√£o paulo"`
- Arquivo: `data/restaurante_italiano_s√£o_paulo.xlsx`

## ‚öôÔ∏è Configura√ß√µes Avan√ßadas

### Modificar Configura√ß√µes do Scrapy

Edite o arquivo `google_business_scraper/settings.py`:

```python
# Delay entre requisi√ß√µes (segundos)
DOWNLOAD_DELAY = 2

# N√∫mero m√°ximo de requisi√ß√µes simult√¢neas
CONCURRENT_REQUESTS = 1

# Ativar AutoThrottle
AUTOTHROTTLE_ENABLED = True
AUTOTHROTTLE_START_DELAY = 1
AUTOTHROTTLE_MAX_DELAY = 10
```

### Personalizar User-Agents

O middleware `RotateUserAgentMiddleware` rotaciona automaticamente os user-agents. Para personalizar, edite `middlewares.py`.

## üêõ Solu√ß√£o de Problemas

### Erro: "cannot decode the response from unsupported encoding 'br'"
```bash
pip install brotli brotlicffi
```

### Erro: "Response content isn't text"
- Verifique sua conex√£o com a internet
- O Google pode estar bloqueando requisi√ß√µes
- Execute novamente ap√≥s alguns minutos

### Arquivo Excel vazio
- Verifique os logs para erros de extra√ß√£o
- O arquivo `debug_page.html` ser√° criado para an√°lise
- Tente com um termo de busca diferente

### Spider n√£o encontrado
```bash
# Certifique-se de estar no diret√≥rio correto
cd google-business-scraper-scrapy

# Verifique se o spider existe
scrapy list
```

## üìù Logs e Debug

### Visualizar Logs Detalhados
```bash
python3 run_scraper.py --search "sua busca" --max-results 50 2>&1 | tee scraper.log
```

### Arquivos de Debug Gerados
- `debug_page.html` - HTML da p√°gina processada
- `debug_raw_response.html` - Resposta bruta em caso de erro

### N√≠veis de Log
- `INFO` - Informa√ß√µes gerais
- `WARNING` - Avisos
- `ERROR` - Erros cr√≠ticos
- `DEBUG` - Informa√ß√µes detalhadas

## üß™ Testes

### Testar Pipeline
```bash
python3 test_pipeline.py
```

### Testar Spider Diretamente
```bash
cd google_business_scraper
scrapy crawl business -a search_query="teste" -a max_results=5
```

## üîß Desenvolvimento

### Adicionar Novos Seletores CSS

Edite `business_spider.py` e adicione novos seletores no array `business_selectors`:

```python
business_selectors = [
    'div[data-cid]',
    '.VkpGBb',
    '.rllt__details',
    '.seu-novo-seletor',  # Adicione aqui
]
```

### Modificar Campos Extra√≠dos

Edite `items.py` para adicionar novos campos:

```python
class BusinessItem(scrapy.Item):
    name = scrapy.Field()
    rating = scrapy.Field()
    # Adicione novos campos aqui
    phone = scrapy.Field()
    website = scrapy.Field()
```

## üìã Requisitos do Sistema

- **Python**: 3.8 ou superior
- **Sistema Operacional**: Windows, macOS, Linux
- **Mem√≥ria RAM**: M√≠nimo 512MB
- **Espa√ßo em Disco**: 100MB para instala√ß√£o + espa√ßo para dados

## ü§ù Contribui√ß√£o

1. Fork o projeto
2. Crie uma branch para sua feature (`git checkout -b feature/AmazingFeature`)
3. Commit suas mudan√ßas (`git commit -m 'Add some AmazingFeature'`)
4. Push para a branch (`git push origin feature/AmazingFeature`)
5. Abra um Pull Request

## üìÑ Licen√ßa

Este projeto est√° sob a licen√ßa MIT. Veja o arquivo `LICENSE` para mais detalhes.

## ‚ö†Ô∏è Aviso Legal

Este scraper √© destinado apenas para fins educacionais e de pesquisa. Certifique-se de:

- Respeitar os Termos de Servi√ßo do Google
- N√£o fazer requisi√ß√µes excessivas
- Usar os dados de forma √©tica e legal
- Considerar implementar delays maiores para uso em produ√ß√£o
